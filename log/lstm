
1 EPOCH 0 batch: train loss 0.7171657085418701
1 EPOCH 50 batch: train loss 0.7000522017478943
1 EPOCH 100 batch: train loss 0.6963816285133362
1 EPOCH 150 batch: train loss 0.6936410069465637
1 EPOCH 200 batch: train loss 0.6899309754371643
1 EPOCH 250 batch: train loss 0.6915014982223511
1 EPOCH 300 batch: train loss 0.6823613047599792
1 EPOCH 350 batch: train loss 0.6890947818756104
2 EPOCH 0 batch: train loss 0.6770695447921753
2 EPOCH 50 batch: train loss 0.6830770969390869
2 EPOCH 100 batch: train loss 0.6712618470191956
2 EPOCH 150 batch: train loss 0.6928236484527588
2 EPOCH 200 batch: train loss 0.6752138137817383
2 EPOCH 250 batch: train loss 0.6433968544006348
2 EPOCH 300 batch: train loss 0.6615853905677795
2 EPOCH 350 batch: train loss 0.6579654812812805
3 EPOCH 0 batch: train loss 0.646631121635437
3 EPOCH 50 batch: train loss 0.66378253698349
3 EPOCH 100 batch: train loss 0.669662594795227
3 EPOCH 150 batch: train loss 0.6201437711715698
3 EPOCH 200 batch: train loss 0.6534991264343262
3 EPOCH 250 batch: train loss 0.6358962059020996
3 EPOCH 300 batch: train loss 0.6167148351669312
3 EPOCH 350 batch: train loss 0.6128396987915039
4 EPOCH 0 batch: train loss 0.6373251080513
4 EPOCH 50 batch: train loss 0.6542664766311646
4 EPOCH 100 batch: train loss 0.6194055080413818
4 EPOCH 150 batch: train loss 0.6456348299980164
4 EPOCH 200 batch: train loss 0.5993219017982483
4 EPOCH 250 batch: train loss 0.5973044633865356
4 EPOCH 300 batch: train loss 0.6428080797195435
4 EPOCH 350 batch: train loss 0.5732854604721069
5 EPOCH 0 batch: train loss 0.5923246741294861
5 EPOCH 50 batch: train loss 0.5762037038803101
5 EPOCH 100 batch: train loss 0.6394031047821045
5 EPOCH 150 batch: train loss 0.5488670468330383
5 EPOCH 200 batch: train loss 0.6461498737335205
5 EPOCH 250 batch: train loss 0.5438268184661865
5 EPOCH 300 batch: train loss 0.5723007917404175
5 EPOCH 350 batch: train loss 0.6212339401245117
6 EPOCH 0 batch: train loss 0.5231788754463196
6 EPOCH 50 batch: train loss 0.5482293963432312
6 EPOCH 100 batch: train loss 0.5423249006271362
6 EPOCH 150 batch: train loss 0.4970110058784485
6 EPOCH 200 batch: train loss 0.5809361338615417
6 EPOCH 250 batch: train loss 0.491353303194046
6 EPOCH 300 batch: train loss 0.589522659778595
6 EPOCH 350 batch: train loss 0.5160511136054993
7 EPOCH 0 batch: train loss 0.5626288652420044
7 EPOCH 50 batch: train loss 0.4535309374332428
7 EPOCH 100 batch: train loss 0.47587665915489197
7 EPOCH 150 batch: train loss 0.4609392583370209
7 EPOCH 200 batch: train loss 0.5388181805610657
7 EPOCH 250 batch: train loss 0.43282943964004517
7 EPOCH 300 batch: train loss 0.5282518863677979
7 EPOCH 350 batch: train loss 0.5440990924835205
8 EPOCH 0 batch: train loss 0.4719592332839966
8 EPOCH 50 batch: train loss 0.5654622912406921
8 EPOCH 100 batch: train loss 0.5106870532035828
8 EPOCH 150 batch: train loss 0.5471146106719971
8 EPOCH 200 batch: train loss 0.5307227373123169
8 EPOCH 250 batch: train loss 0.5461980700492859
8 EPOCH 300 batch: train loss 0.5271114110946655
8 EPOCH 350 batch: train loss 0.41764965653419495
9 EPOCH 0 batch: train loss 0.5123294591903687
9 EPOCH 50 batch: train loss 0.5020638108253479
9 EPOCH 100 batch: train loss 0.4663960635662079
9 EPOCH 150 batch: train loss 0.4445890188217163
9 EPOCH 200 batch: train loss 0.5625861287117004
9 EPOCH 250 batch: train loss 0.4140450358390808
9 EPOCH 300 batch: train loss 0.46338701248168945
9 EPOCH 350 batch: train loss 0.44229960441589355
10 EPOCH 0 batch: train loss 0.4513891935348511
10 EPOCH 50 batch: train loss 0.5556960105895996
10 EPOCH 100 batch: train loss 0.43646177649497986
10 EPOCH 150 batch: train loss 0.539026141166687
10 EPOCH 200 batch: train loss 0.5573431849479675
10 EPOCH 250 batch: train loss 0.6230864524841309
10 EPOCH 300 batch: train loss 0.599585771560669
10 EPOCH 350 batch: train loss 0.3754977881908417
11 EPOCH 0 batch: train loss 0.454504132270813
11 EPOCH 50 batch: train loss 0.4635147452354431
11 EPOCH 100 batch: train loss 0.3697989881038666
11 EPOCH 150 batch: train loss 0.46989262104034424
11 EPOCH 200 batch: train loss 0.35450470447540283
11 EPOCH 250 batch: train loss 0.3745135962963104
11 EPOCH 300 batch: train loss 0.38140612840652466
11 EPOCH 350 batch: train loss 0.5625799894332886
12 EPOCH 0 batch: train loss 0.45553410053253174
12 EPOCH 50 batch: train loss 0.39283832907676697
12 EPOCH 100 batch: train loss 0.45717042684555054
12 EPOCH 150 batch: train loss 0.3518623411655426
12 EPOCH 200 batch: train loss 0.5071790814399719
12 EPOCH 250 batch: train loss 0.40927261114120483
12 EPOCH 300 batch: train loss 0.42223885655403137
12 EPOCH 350 batch: train loss 0.5205905437469482
13 EPOCH 0 batch: train loss 0.39624589681625366
13 EPOCH 50 batch: train loss 0.5126914381980896
13 EPOCH 100 batch: train loss 0.3092004954814911
13 EPOCH 150 batch: train loss 0.39997899532318115
13 EPOCH 200 batch: train loss 0.4302622973918915
13 EPOCH 250 batch: train loss 0.5176994800567627
13 EPOCH 300 batch: train loss 0.36971232295036316
13 EPOCH 350 batch: train loss 0.4441380798816681
14 EPOCH 0 batch: train loss 0.4594559371471405
14 EPOCH 50 batch: train loss 0.3991949260234833
14 EPOCH 100 batch: train loss 0.3940390348434448
14 EPOCH 150 batch: train loss 0.3772190511226654
14 EPOCH 200 batch: train loss 0.44099581241607666
14 EPOCH 250 batch: train loss 0.4768684208393097
14 EPOCH 300 batch: train loss 0.5261286497116089
14 EPOCH 350 batch: train loss 0.30871567130088806

15 EPOCH 0 batch: train loss 0.4853588938713074
15 EPOCH 50 batch: train loss 0.37287768721580505
15 EPOCH 100 batch: train loss 0.39106687903404236
15 EPOCH 150 batch: train loss 0.3835965692996979
15 EPOCH 200 batch: train loss 0.24304579198360443
15 EPOCH 250 batch: train loss 0.36999744176864624
15 EPOCH 300 batch: train loss 0.4706144332885742
15 EPOCH 350 batch: train loss 0.37886324524879456
16 EPOCH 0 batch: train loss 0.4194580316543579
16 EPOCH 50 batch: train loss 0.43792545795440674
16 EPOCH 100 batch: train loss 0.45162850618362427
16 EPOCH 150 batch: train loss 0.3880743384361267
16 EPOCH 200 batch: train loss 0.409309446811676
16 EPOCH 250 batch: train loss 0.4365452826023102
16 EPOCH 300 batch: train loss 0.3572446405887604
16 EPOCH 350 batch: train loss 0.3643449544906616
17 EPOCH 0 batch: train loss 0.37514784932136536
17 EPOCH 50 batch: train loss 0.43896758556365967
17 EPOCH 100 batch: train loss 0.48567473888397217
17 EPOCH 150 batch: train loss 0.47472044825553894
17 EPOCH 200 batch: train loss 0.431924432516098
17 EPOCH 250 batch: train loss 0.3220521807670593
17 EPOCH 300 batch: train loss 0.5315722227096558
17 EPOCH 350 batch: train loss 0.331966757774353
18 EPOCH 0 batch: train loss 0.4722875654697418
18 EPOCH 50 batch: train loss 0.37318238615989685
18 EPOCH 100 batch: train loss 0.4361512064933777
18 EPOCH 150 batch: train loss 0.26396867632865906
18 EPOCH 200 batch: train loss 0.4036771357059479
18 EPOCH 250 batch: train loss 0.31474462151527405
18 EPOCH 300 batch: train loss 0.3042609393596649
18 EPOCH 350 batch: train loss 0.45508700609207153
19 EPOCH 0 batch: train loss 0.3801267445087433
19 EPOCH 50 batch: train loss 0.48758190870285034
19 EPOCH 100 batch: train loss 0.418017715215683
19 EPOCH 150 batch: train loss 0.3366125524044037
19 EPOCH 200 batch: train loss 0.40899068117141724
19 EPOCH 250 batch: train loss 0.43275922536849976
19 EPOCH 300 batch: train loss 0.46696287393569946
19 EPOCH 350 batch: train loss 0.35527941584587097
best accuracy: 0.8193255066871643






  Environment lstm     View current
Filter text
filter   online
Xâ¤“
[0613_145810]user config:
[0613_145810]env lstm
[0613_145810]hidden_dim 128
[0613_145810]max_seq_len 200
[0613_145810]batch_size 64
[0613_145810]embedding_dim 100
[0613_145810]grad_clip 0.1
[0613_145810]learning_rate 2e-05
[0613_145810]model lstm
[0613_145810]dataset imdb
[0613_145810]keep_dropout 0.8
[0613_145810]max_epoch 20
[0613_145810]embedding_file glove.6b.300
[0613_145810]embedding_training False
[0613_145810]kernel_sizes [1, 3, 3]
[0613_145810]kernel_nums [256, 256, 256]
[0613_145810]lstm_mean mean
[0613_145810]lstm_layers 1
[0613_145810]embedding_dir .glove/glove.6B.300d.txt
[0613_145810]from_torchtext False
[0613_145810]gpu 0
[0613_145810]use_cuda False
[0613_150607]0 EPOCH, accuaracy : 0.5130115151405334
[0613_151525]1 EPOCH, accuaracy : 0.5943334102630615
[0613_152545]2 EPOCH, accuaracy : 0.6633552312850952
[0613_153429]3 EPOCH, accuaracy : 0.6721147894859314
[0613_154159]4 EPOCH, accuaracy : 0.7248241901397705
[0613_155010]5 EPOCH, accuaracy : 0.7358855605125427
[0613_155830]6 EPOCH, accuaracy : 0.7479619383811951
[0613_160631]7 EPOCH, accuaracy : 0.7622122764587402
[0613_161418]8 EPOCH, accuaracy : 0.7669597268104553
[0613_162230]9 EPOCH, accuaracy : 0.7699568867683411
[0613_163037]10 EPOCH, accuaracy : 0.7740408778190613
[0613_163907]11 EPOCH, accuaracy : 0.7926950454711914
[0613_164737]12 EPOCH, accuaracy : 0.7880674600601196
[0613_165717]13 EPOCH, accuaracy : 0.8043158054351807
[0613_174717]14 EPOCH, accuaracy : 0.8033727407455444
[0613_180211]15 EPOCH, accuaracy : 0.8102301359176636
[0613_182659]16 EPOCH, accuaracy : 0.8159606456756592
[0613_193333]17 EPOCH, accuaracy : 0.8091272115707397
[0613_200454]18 EPOCH, accuaracy : 0.8193255066871643
[0613_203739]19 EPOCH, accuaracy : 0.8092391490936279
